apiVersion: apps/v1
kind: Deployment
metadata:
  name: web-deployment
spec:        
  selector:
    matchLabels:
      app: web-app
  strategy:
    rollingUpdate:                      # rollingUpdate для обеспечения максимальной доступности при обновлении подов. Так они будут обновляться по-очереди
      maxSurge: 1
      maxUnavailable: 1
    type: RollingUpdate
  template:
    metadata:
      labels:
        app: web-app
    spec:
      topologySpreadConstraints:      # тк у нас мультизональный кластер. Для равномерного распределения нагрузки
        - maxSkew: 1                  # тк у нас 3 зоны с 5 нод их будет невозможно равномерно разместить. Максимальное распределение 2,2,1. Поэтому максимальный перекос это 1
          topologyKey: zone
          whenUnsatisfiable: DoNotSchedule        # тк у нас 3 зоны с 5 нод и их невозможно равномерно разместить
          labelSelector:
            matchLabels:
              app: web-app
      containers:
      - image: nginx:1.12              # просто для примера
        name: nginx
        ports:
        - containerPort: 80
        readinessProbe:                # для максимальной отказоустойчивости я решил добавить все 3 пробы
          failureThreshold: 3
          httpGet:                     # тк в условии web-приложение выбрал http проверку
            path: /healthz
            port: 80
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 5
        livenessProbe:
          failureThreshold: 3
          httpGet:
            path: /healthz
            port: 80
          periodSeconds: 30
          successThreshold: 1
          timeoutSeconds: 5
          initialDelaySeconds: 5       # тк в условии 5-10 сек инициализация, проба заработает через 5 секунд
        startupProbe:
          failureThreshold: 18         # в стартап пробе числа 18 и 10 взяты из расчета что максимальный запуск будет составлять 3 минуты
          httpGet:
            path: /healthz
            port: 80
          periodSeconds: 10   
        resources: 
          requests:                    # # также если отказоустойчивость приоритетнее чем потребление ресурсов, то можно указать одинаковое потребление 'cpu' и 'memory' для получения QoS Class Guaranteed. При котором приложение будет иметь приоритет выше, но в нашем случае будут зарезервированы излишние ресурсы
            cpu: 100m                  # тк стандартное 0.1 cpu  
            memory: 128Mi              # тк стандартное около 128 Mi
          limits: 
            cpu: 200m                  # предположим, что при запуске "значительно больше ресурсов" это в 2 раз, чем "в дальнейшем" 
            memory: 160Mi              # на 25% больше стандартного потребления


---

apiVersion: autoscaling/v2             # тк во 2й версии можно управлять политиками как для масштабирования вверх, так и вниз.
kind: HorizontalPodAutoscaler          # тк у нас пик днем, а ночью запросов меньше, то на ночь количество подов будет падать до 2, а потом снова подниматься. Также поставим масштабирование не только в меньшую сторону, но и на всякий случай 2 пода сверх тех, которые держат пиковую нагрузку (4) 
metadata: 
  labels:
    app: web-app
  name: web-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: web-deployment
  minReplicas: 2
  maxReplicas: 6
  
  behavior:
    scaleDown:                          # если использование cpu падает до 40 % у нас падают поды до 2
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 40
        periodSeconds: 20
    scaleUp:                            # если использование cpu увеличивается до 140 % поднимаются 6 подов
      stabilizationWindowSeconds: 0
      policies: 
      - type: Percent
        value: 140                 
        periodSeconds: 10

